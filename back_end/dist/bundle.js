/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	"use strict";
/******/ 	var __webpack_modules__ = ({

/***/ "./js/faceApiSetup.js":
/*!****************************!*\
  !*** ./js/faceApiSetup.js ***!
  \****************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

eval("__webpack_require__.r(__webpack_exports__);\nObject(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }());\n// import * as faceapi from '@vladmandic/face-api';\n\n// async function setupCamera() {\n//   const videoElement = document.getElementById('camera-stream');\n//   if (navigator.mediaDevices.getUserMedia) {\n//     const stream = await navigator.mediaDevices.getUserMedia({ video: {} });\n//     videoElement.srcObject = stream;\n//   }\n// }\n\n// async function runFaceApi() {\n//   await faceapi.nets.tinyFaceDetector.loadFromUri('/models');\n//   const videoElement = document.getElementById('camera-stream');\n//   videoElement.addEventListener('play', () => {\n//     const canvas = faceapi.createCanvasFromMedia(videoElement);\n//     document.body.append(canvas);\n//     const displaySize = { width: videoElement.width, height: videoElement.height };\n//     faceapi.matchDimensions(canvas, displaySize);\n//     setInterval(async () => {\n//       const detections = await faceapi.detectAllFaces(videoElement, new faceapi.TinyFaceDetectorOptions());\n//       const resizedDetections = faceapi.resizeResults(detections, displaySize);\n//       canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);\n//       faceapi.draw.drawDetections(canvas, resizedDetections);\n//     }, 100);\n//   });\n// }\n\n// // We run the setupCamera function and once it's resolved we run the faceApi function.\n// setupCamera().then(runFaceApi);\n\n/**\n * FaceAPI Demo for Browsers\n * Loaded via `webcam.html`\n */\n\n// import * as faceapi from '../dist/face-api.esm.js'; // use when in dev mode\n // use when downloading face-api as npm\n\n// configuration options\nconst modelPath = '../models/'; // path to model folder that will be loaded using http\n// const modelPath = 'https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/'; // path to model folder that will be loaded using http\nconst minScore = 0.2; // minimum score\nconst maxResults = 5; // maximum number of results to return\nlet optionsSSDMobileNet;\n\n// helper function to pretty-print json object to string\nfunction str(json) {\n  let text = '<font color=\"lightblue\">';\n  text += json ? JSON.stringify(json).replace(/{|}|\"|\\[|\\]/g, '').replace(/,/g, ', ') : '';\n  text += '</font>';\n  return text;\n}\n\n// helper function to print strings to html document as a log\nfunction log(...txt) {\n  console.log(...txt); // eslint-disable-line no-console\n  const div = document.getElementById('log');\n  if (div) div.innerHTML += `<br>${txt}`;\n}\n\n// helper function to draw detected faces\nfunction drawFaces(canvas, data, fps) {\n  const ctx = canvas.getContext('2d', { willReadFrequently: true });\n  if (!ctx) return;\n  ctx.clearRect(0, 0, canvas.width, canvas.height);\n  // draw title\n  ctx.font = 'small-caps 20px \"Segoe UI\"';\n  ctx.fillStyle = 'white';\n  ctx.fillText(`FPS: ${fps}`, 10, 25);\n  for (const person of data) {\n    // draw box around each face\n    ctx.lineWidth = 3;\n    ctx.strokeStyle = 'deepskyblue';\n    ctx.fillStyle = 'deepskyblue';\n    ctx.globalAlpha = 0.6;\n    ctx.beginPath();\n    ctx.rect(person.detection.box.x, person.detection.box.y, person.detection.box.width, person.detection.box.height);\n    ctx.stroke();\n    ctx.globalAlpha = 1;\n    // draw text labels\n    const expression = Object.entries(person.expressions).sort((a, b) => b[1] - a[1]);\n    ctx.fillStyle = 'black';\n    ctx.fillText(`gender: ${Math.round(100 * person.genderProbability)}% ${person.gender}`, person.detection.box.x, person.detection.box.y - 59);\n    ctx.fillText(`expression: ${Math.round(100 * expression[0][1])}% ${expression[0][0]}`, person.detection.box.x, person.detection.box.y - 41);\n    ctx.fillText(`age: ${Math.round(person.age)} years`, person.detection.box.x, person.detection.box.y - 23);\n    ctx.fillText(`roll:${person.angle.roll}° pitch:${person.angle.pitch}° yaw:${person.angle.yaw}°`, person.detection.box.x, person.detection.box.y - 5);\n    ctx.fillStyle = 'lightblue';\n    ctx.fillText(`gender: ${Math.round(100 * person.genderProbability)}% ${person.gender}`, person.detection.box.x, person.detection.box.y - 60);\n    ctx.fillText(`expression: ${Math.round(100 * expression[0][1])}% ${expression[0][0]}`, person.detection.box.x, person.detection.box.y - 42);\n    ctx.fillText(`age: ${Math.round(person.age)} years`, person.detection.box.x, person.detection.box.y - 24);\n    ctx.fillText(`roll:${person.angle.roll}° pitch:${person.angle.pitch}° yaw:${person.angle.yaw}°`, person.detection.box.x, person.detection.box.y - 6);\n    // draw face points for each face\n    ctx.globalAlpha = 0.8;\n    ctx.fillStyle = 'lightblue';\n    const pointSize = 2;\n    for (let i = 0; i < person.landmarks.positions.length; i++) {\n      ctx.beginPath();\n      ctx.arc(person.landmarks.positions[i].x, person.landmarks.positions[i].y, pointSize, 0, 2 * Math.PI);\n      ctx.fill();\n    }\n  }\n}\n\nasync function detectVideo(video, canvas) {\n  if (!video || video.paused) return false;\n  const t0 = performance.now();\n  Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())(video, optionsSSDMobileNet)\n    .withFaceLandmarks()\n    .withFaceExpressions()\n    // .withFaceDescriptors()\n    .withAgeAndGender()\n    .then((result) => {\n      const fps = 1000 / (performance.now() - t0);\n      drawFaces(canvas, result, fps.toLocaleString());\n      requestAnimationFrame(() => detectVideo(video, canvas));\n      return true;\n    })\n    .catch((err) => {\n      log(`Detect Error: ${str(err)}`);\n      return false;\n    });\n  return false;\n}\n\n// just initialize everything and call main function\nasync function setupCamera() {\n  const video = document.getElementById('camera-stream');\n  const canvas = document.getElementById('canvas');\n  if (!video || !canvas) return null;\n\n  log('Setting up camera');\n  // setup webcam. note that navigator.mediaDevices requires that page is accessed via https\n  if (!navigator.mediaDevices) {\n    log('Camera Error: access not supported');\n    return null;\n  }\n  let stream;\n  const constraints = { audio: false, video: { facingMode: 'user', resizeMode: 'crop-and-scale' } };\n  if (window.innerWidth > window.innerHeight) constraints.video.width = { ideal: window.innerWidth };\n  else constraints.video.height = { ideal: window.innerHeight };\n  try {\n    stream = await navigator.mediaDevices.getUserMedia(constraints);\n  } catch (err) {\n    if (err.name === 'PermissionDeniedError' || err.name === 'NotAllowedError') log(`Camera Error: camera permission denied: ${err.message || err}`);\n    if (err.name === 'SourceUnavailableError') log(`Camera Error: camera not available: ${err.message || err}`);\n    return null;\n  }\n  if (stream) {\n    video.srcObject = stream;\n  } else {\n    log('Camera Error: stream empty');\n    return null;\n  }\n  const track = stream.getVideoTracks()[0];\n  const settings = track.getSettings();\n  if (settings.deviceId) delete settings.deviceId;\n  if (settings.groupId) delete settings.groupId;\n  if (settings.aspectRatio) settings.aspectRatio = Math.trunc(100 * settings.aspectRatio) / 100;\n  log(`Camera active: ${track.label}`);\n  log(`Camera settings: ${str(settings)}`);\n  // canvas.addEventListener('click', () => {\n  //   if (video && video.readyState >= 2) {\n  //     if (video.paused) {\n  //       video.play();\n  //       detectVideo(video, canvas);\n  //     } else {\n  //       video.pause();\n  //     }\n  //   }\n  //   log(`Camera state: ${video.paused ? 'paused' : 'playing'}`);\n  // });\n  return new Promise((resolve) => {\n    video.onloadeddata = async () => {\n      canvas.width = video.videoWidth;\n      canvas.height = video.videoHeight;\n      video.play();\n      detectVideo(video, canvas);\n      resolve(true);\n    };\n  });\n}\n\nasync function setupFaceAPI() {\n  // load face-api models\n  // log('Models loading');\n  // await faceapi.nets.tinyFaceDetector.load(modelPath); // using ssdMobilenetv1\n  await Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()).ssdMobilenetv1.load(modelPath);\n  await Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()).ageGenderNet.load(modelPath);\n  await Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()).faceLandmark68Net.load(modelPath);\n  await Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()).faceRecognitionNet.load(modelPath);\n  await Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()).faceExpressionNet.load(modelPath);\n  optionsSSDMobileNet = new Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())({ minConfidence: minScore, maxResults });\n  // check tf engine state\n  log(`Models loaded: ${str(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()).engine().state.numTensors)} tensors`);\n}\n\nasync function main() {\n  // initialize tfjs\n  log('FaceAPI WebCam Test');\n\n  // if you want to use wasm backend location for wasm binaries must be specified\n  // await faceapi.tf?.setWasmPaths(`https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-wasm@${faceapi.tf.version_core}/dist/`);\n  // await faceapi.tf?.setBackend('wasm');\n  // log(`WASM SIMD: ${await faceapi.tf?.env().getAsync('WASM_HAS_SIMD_SUPPORT')} Threads: ${await faceapi.tf?.env().getAsync('WASM_HAS_MULTITHREAD_SUPPORT') ? 'Multi' : 'Single'}`);\n\n  // default is webgl backend\n  await Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()).setBackend('webgl');\n  await Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()).ready();\n\n  // tfjs optimizations\n  if (Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())?.env().flagRegistry.CANVAS2D_WILL_READ_FREQUENTLY) Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()).env().set('CANVAS2D_WILL_READ_FREQUENTLY', true);\n  if (Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())?.env().flagRegistry.WEBGL_EXP_CONV) Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()).env().set('WEBGL_EXP_CONV', true);\n  if (Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())?.env().flagRegistry.WEBGL_EXP_CONV) Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()).env().set('WEBGL_EXP_CONV', true);\n\n  // check version\n  log(`Version: FaceAPI ${str(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())?.version || '(not loaded)')} TensorFlow/JS ${str(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())?.version_core || '(not loaded)')} Backend: ${str(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module '@vladmandic/face-api'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())?.getBackend() || '(not loaded)')}`);\n\n  await setupFaceAPI();\n  await setupCamera();\n}\n\n// start processing as soon as page is loaded\nwindow.onload = main;\n\n\n//# sourceURL=webpack://websdk-cdn/./js/faceApiSetup.js?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The require scope
/******/ 	var __webpack_require__ = {};
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = {};
/******/ 	__webpack_modules__["./js/faceApiSetup.js"](0, __webpack_exports__, __webpack_require__);
/******/ 	
/******/ })()
;